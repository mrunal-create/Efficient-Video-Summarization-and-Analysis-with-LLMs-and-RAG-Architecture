{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8120216,"sourceType":"datasetVersion","datasetId":4798041}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Environment setup","metadata":{"id":"EpGWUswStQEZ"}},{"cell_type":"code","source":"# !pip install -q -U transformers peft accelerate optimum\n# !pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/\n# !pip install langchain\n# !pip install einops\n# !pip install optimum\n# !pip install rouge_score\n# !pip install bert_score\n# !pip install pytube ffmpeg-python --quiet\n# !pip install SpeechRecognition --quiet\n# !pip install pydub --quiet\n# !pip install moviepy --quiet\n# !pip install openai --quiet\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJ57vxf5ih2v","outputId":"92d77c3f-23d3-4de1-eba5-c388d9ffb6d9","execution":{"iopub.status.busy":"2024-04-14T17:46:12.947284Z","iopub.execute_input":"2024-04-14T17:46:12.948165Z","iopub.status.idle":"2024-04-14T17:46:12.952927Z","shell.execute_reply.started":"2024-04-14T17:46:12.948130Z","shell.execute_reply":"2024-04-14T17:46:12.951759Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"markdown","source":"# Environment settings","metadata":{"id":"vflg3lYz1Bws"}},{"cell_type":"code","source":"#client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"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\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T22:44:18.283437Z","iopub.execute_input":"2024-04-14T22:44:18.283783Z","iopub.status.idle":"2024-04-14T22:44:18.302060Z","shell.execute_reply.started":"2024-04-14T22:44:18.283755Z","shell.execute_reply":"2024-04-14T22:44:18.301312Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Import neccessary libraries","metadata":{"id":"XGf07gk3tV7b"}},{"cell_type":"code","source":"import time\nimport numpy as np\nimport math\n# import evaluate\nimport csv\nimport re\nimport pandas as pd\nfrom sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom dotenv import load_dotenv\nfrom pytube import YouTube\nimport ffmpeg\nimport requests\nfrom urllib.parse import urlparse\nimport requests\nimport json\nfrom openai import OpenAI\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport speech_recognition as sr\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport os\n# load_dotenv() ##load all the nevironment variables\nimport os\nimport google.generativeai as genai\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import AutoTokenizer\nfrom transformers import GenerationConfig\nfrom pytube import YouTube\nimport ffmpeg\nimport requests\nfrom urllib.parse import urlparse\nimport requests\nfrom bs4 import BeautifulSoup\nimport json\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom moviepy.editor import *\nimport asyncio\nimport tarfile\nfrom zipfile import ZipFile\nfrom langchain import LLMChain, HuggingFacePipeline, PromptTemplate","metadata":{"id":"BtqOIHeHtQbY","execution":{"iopub.status.busy":"2024-04-14T17:46:12.980348Z","iopub.execute_input":"2024-04-14T17:46:12.980672Z","iopub.status.idle":"2024-04-14T17:46:12.993901Z","shell.execute_reply.started":"2024-04-14T17:46:12.980643Z","shell.execute_reply":"2024-04-14T17:46:12.993067Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"markdown","source":"## Configurations","metadata":{"id":"XeGe4gdg08bs"}},{"cell_type":"code","source":"#Just update model_name here and test out your model , also update id of model in code below cell 12\nconfig={\n    \"model_id\": [\"TheBloke/Llama-2-7b-Chat-GPTQ\",\n                 \"TheBloke/Llama-2-7B-AWQ\",\n                 \"TheBloke/Llama-2-7B-GGUF\",\n                 \"TheBloke/Llama-2-7B-GGML\",\n                 \"TheBloke/Llama-2-7B-fp16\",\n                 \"TheBloke/Llama-2-7B-GPTQ\",\n                 \"TheBloke/llama-2-7B-Guanaco-QLoRA-AWQ\",\n                 \"TheBloke/Llama-2-7B-AWQ\",\n                \"google/flan-t5-large\"],\n    \"hf_token\": \"...\",\n    \"model\": {\n        \"temperature\": 0.7, # [0, 0.7, .0.9, 1.1, 1.3]  Testing iteratively.\n        \"max_length\": 4000,\n        \"top_k\": 10,\n        \"num_return\": 1\n    },\n    \"dataset\": [\n        \"billsum\",\n        \"cnn_dailymail\",\n        \"big_patent\"\n    ],\n    \"eval\": ['rouge', \"bertscore\", 'meteor']\n}\n","metadata":{"id":"Ilgcn7sW06Qu","execution":{"iopub.status.busy":"2024-04-14T17:46:12.995775Z","iopub.execute_input":"2024-04-14T17:46:12.996071Z","iopub.status.idle":"2024-04-14T17:46:13.009951Z","shell.execute_reply.started":"2024-04-14T17:46:12.996038Z","shell.execute_reply":"2024-04-14T17:46:13.009207Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"4B0V3PgStZih"}},{"cell_type":"code","source":"def call_parameter(model):\n    pytorch_total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    untrainable_params = pytorch_total_params - trainable_params\n    print(f'Model {model.__class__.__name__} has {pytorch_total_params} parameters in total\\n'\\\n        f'Trainable parameters: {trainable_params}\\nUntrainable parameters: {untrainable_params}')\n    return pytorch_total_params","metadata":{"id":"mIvth5iatQeJ","execution":{"iopub.status.busy":"2024-04-14T17:46:13.010955Z","iopub.execute_input":"2024-04-14T17:46:13.011292Z","iopub.status.idle":"2024-04-14T17:46:13.024281Z","shell.execute_reply.started":"2024-04-14T17:46:13.011261Z","shell.execute_reply":"2024-04-14T17:46:13.023514Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"markdown","source":"# Model architecture","metadata":{"id":"CxmLQrHytd-m"}},{"cell_type":"code","source":"def generate_model(model_id, config):\n    print(f\"Setting up model {model_id}\")\n    model = AutoModelForCausalLM.from_pretrained(model_id, use_safetensors=True,\n                            device_map='auto', trust_remote_code=True)\n    tokenizer = AutoTokenizer.from_pretrained(model_id,\n                                            device_map='auto', trust_remote_code=True)\n    return model, tokenizer","metadata":{"id":"JxZI5LT83upi","execution":{"iopub.status.busy":"2024-04-14T17:46:13.025475Z","iopub.execute_input":"2024-04-14T17:46:13.025800Z","iopub.status.idle":"2024-04-14T17:46:13.038318Z","shell.execute_reply.started":"2024-04-14T17:46:13.025771Z","shell.execute_reply":"2024-04-14T17:46:13.037545Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"class Agent:\n    def __init__(self, model, tokenizer):\n        self.model = model\n        self.tokenizer = tokenizer\n\n    def __repr__(self):\n        return f'Model {self.model.__class__.__name__}'","metadata":{"id":"jCresULjzlcJ","execution":{"iopub.status.busy":"2024-04-14T17:46:13.039216Z","iopub.execute_input":"2024-04-14T17:46:13.039469Z","iopub.status.idle":"2024-04-14T17:46:13.048994Z","shell.execute_reply.started":"2024-04-14T17:46:13.039447Z","shell.execute_reply":"2024-04-14T17:46:13.048143Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"#Update the model_id index as per model you want to use\nmodel, tokenizer = generate_model(config['model_id'][0], config)\nno_params = call_parameter(model)\nprint(\"=====\"*5)\nprint(f\"Model {config['model_id'][0]} has {no_params} parameters.\")","metadata":{"id":"DYmsnNkXjCRB","execution":{"iopub.status.busy":"2024-04-14T17:46:13.062260Z","iopub.execute_input":"2024-04-14T17:46:13.062543Z","iopub.status.idle":"2024-04-14T17:46:17.380291Z","shell.execute_reply.started":"2024-04-14T17:46:13.062521Z","shell.execute_reply":"2024-04-14T17:46:17.379306Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"Setting up model TheBloke/Llama-2-7b-Chat-GPTQ\nModel LlamaForCausalLM has 262410240 parameters in total\nTrainable parameters: 262410240\nUntrainable parameters: 0\n=========================\nModel TheBloke/Llama-2-7b-Chat-GPTQ has 262410240 parameters.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Experiments","metadata":{"id":"x506HiO4thgt"}},{"cell_type":"markdown","source":"## Implementation","metadata":{"id":"85ujx14hyZbR"}},{"cell_type":"code","source":"class Generator:\n    def __init__(self, config, agent, template):\n        self.agent = agent\n        pipeline = transformers.pipeline(\n            \"text-generation\",\n            model=self.agent.model,\n            tokenizer=self.agent.tokenizer,\n            torch_dtype=torch.bfloat16,\n            trust_remote_code=True,\n            device_map=\"auto\",\n            max_length=config['model']['max_length'],\n            do_sample=True,\n            top_k=config['model']['top_k'],\n            num_return_sequences=config['model']['num_return'],\n            pad_token_id=tokenizer.eos_token_id\n        )\n        llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature': config['model']['temperature']})\n        prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def generate(self, text):\n        result = self.llm_chain.invoke(text)\n        return result","metadata":{"id":"Akq4pDpW52k4","execution":{"iopub.status.busy":"2024-04-14T17:46:17.383319Z","iopub.execute_input":"2024-04-14T17:46:17.383653Z","iopub.status.idle":"2024-04-14T17:46:17.391372Z","shell.execute_reply.started":"2024-04-14T17:46:17.383626Z","shell.execute_reply":"2024-04-14T17:46:17.390385Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"template = \"\"\"\n              Write a summary of the following text delimited by triple backticks.\n              Return your response which covers the key points of the text.\n              ```{text}```\n              SUMMARY:\n           \"\"\"","metadata":{"id":"dQsvQqZ-tQpH","execution":{"iopub.status.busy":"2024-04-14T17:46:17.392461Z","iopub.execute_input":"2024-04-14T17:46:17.392711Z","iopub.status.idle":"2024-04-14T17:46:17.409239Z","shell.execute_reply.started":"2024-04-14T17:46:17.392690Z","shell.execute_reply":"2024-04-14T17:46:17.408371Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"agent = Agent(model, tokenizer)\nllm_agent = Generator(config, agent, template)","metadata":{"id":"IsSok7Am0--B","execution":{"iopub.status.busy":"2024-04-14T17:46:17.410310Z","iopub.execute_input":"2024-04-14T17:46:17.410625Z","iopub.status.idle":"2024-04-14T17:46:17.427509Z","shell.execute_reply.started":"2024-04-14T17:46:17.410579Z","shell.execute_reply":"2024-04-14T17:46:17.426554Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":"Youtube links I tested on:\n\n* \"https://www.youtube.com/watch?v=U1omz0B9FTw\"\n \"https://www.youtube.com/watch?v=d_qvLDhkg00\"\n* https://www.youtube.com/watch?v=h5id4erwD4s\n* https://www.youtube.com/watch?v=tl30y5OOfqQ,\n* https://www.youtube.com/watch?v=6bJTEZnTT5A\n* https://www.youtube.com/watch?v=SZorAJ4I-sA\n* https://www.youtube.com/watch?v=V_2QqOEwzYU\n* https://www.youtube.com/watch?v=yw-E__nDkKU\n* https://www.youtube.com/watch?v=en2bmeB4QUo\n* https://www.youtube.com/watch?v=ch5EQgzfroo","metadata":{}},{"cell_type":"markdown","source":"# **SUMMARIZATION PART**","metadata":{}},{"cell_type":"code","source":"#final = dict()\n#intialize dictionary to store your transcript and summaries generated \n#run only once in start","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_mp4_playable(file_path):\n  try:\n      # Probe the file to get information about it\n      probe = ffmpeg.probe(file_path)\n      # Check if the file format is recognized as video\n      if 'streams' in probe and any(stream['codec_type'] == 'video' for stream in probe['streams']):\n          print(\"MP4 file is playable.\")\n          return True\n      else:\n          print(\"MP4 file is corrupt or non-playable.\")\n          return False\n  except ffmpeg.Error as e:\n      #print(\"Error occurred:\", e.stderr)\n      return False\n# Extract audio from given video\ndef extract_audio(link, output_file_path):\n  if urlparse(link).netloc == \"www.youtube.com\":\n    yt = YouTube(link)\n    video_path = yt.streams[0].url\n\n  elif urlparse(link).netloc == \"www.linkedin.com\":\n    r = requests.get(link)\n    soup = BeautifulSoup(r.content, 'html.parser')\n    data_linkedin = json.loads(soup.find('script', type='application/ld+json').text)\n    if data_linkedin['isAccessibleForFree'] == True:\n      video_path = json.loads(soup.video['data-sources'])[0]['src']\n    else:\n      print(\"Sorry! Can't extract audio. Please make sure the video is free for access.\")\n      return\n\n  elif urlparse(link).netloc == \"www.coursera.org\":\n    r = requests.get(link)\n    soup = BeautifulSoup(r.content, 'html.parser')\n    data_coursera = json.loads(soup.find('script', type='application/ld+json').text)\n    video_path = data_coursera['@graph'][1]['contentURL']\n\n  elif urlparse(link).netloc not in [\"www.youtube.com\", \"www.linkedin.com\", \"www.coursera.org\"]:\n    print(\"Sorry! Can't extract audio. Please make sure the video link is valid.\")\n    return\n\n\n  else:\n    if(is_mp4_playable(link)):\n      video_path = link\n    else:\n      print(\"Sorry! Can't extract audio. Please make sure the video file exists and is not corrupted.\")\n      return\n\n\n  audio, err = (\n      ffmpeg\n      .input(video_path)\n      .output(\"pipe:\", format='mp3', acodec='libmp3lame', audio_bitrate='320k')\n      .run(capture_stdout=True)\n  )\n\n\n  with open(output_file_path, 'wb') as f:\n      f.write(audio)\n\n  print(\"Audio extraction complete.\")\ndef divide_audio_chunks(audio_file, chunksize = 30000):\n    mp3_audio = AudioSegment.from_mp3(audio_file)\n    # Split the audio into chunks\n    chunks = make_chunks(mp3_audio, chunksize)\n    return chunks\n\ndef process_chunks(audio_chunks):\n  whole_speech = \"\"\n  recognizer = sr.Recognizer()\n  for i, chunk in enumerate(audio_chunks):\n    audio = chunk.export(format=\"wav\")\n    with sr.AudioFile(audio) as source:\n      audio_data = recognizer.record(source)\n      try:\n        text = recognizer.recognize_google(audio_data)\n        #print(f\"Chunk {i+1}: {text}\")\n        whole_speech += text\n      except sr.UnknownValueError:\n        print(f\"Chunk {i+1}, Google Speech Recognition could not understand audio\")\n      except sr.RequestError as e:\n        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n  return whole_speech\n## getting the transcript data from yt videos\ndef extract_audio_transcript_details(youtube_video_url):\n\n    try:\n        sound_file='audio.mp3'\n        extract_audio(youtube_video_url,sound_file)\n        #video_id=youtube_video_url.split(\"=\")[1]\n        audio_chunks = divide_audio_chunks(sound_file)\n        speech = process_chunks(audio_chunks)\n        return speech\n\n    except Exception as e:\n        raise e\n    \nyoutube_link = \"https://www.youtube.com/watch?v=ch5EQgzfroo\"\nif youtube_link:\n    video_id = youtube_link.split(\"=\")[1]\n    transcript_text=extract_audio_transcript_details(youtube_link)\n    if transcript_text:\n        generated_sample = llm_agent.generate(transcript_text)\n        print(\"SUMMARY\")\n        text=generated_sample[\"text\"].split(\"SUMMARY\")[1]\n        print(text)\n        final[transcript_text]=generated_sample[\"text\"].split(\"SUMMARY\")[1]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:46:17.430756Z","iopub.execute_input":"2024-04-14T17:46:17.431048Z","iopub.status.idle":"2024-04-14T17:53:20.929433Z","shell.execute_reply.started":"2024-04-14T17:46:17.431013Z","shell.execute_reply":"2024-04-14T17:53:20.928406Z"},"trusted":true},"execution_count":203,"outputs":[{"name":"stderr","text":"ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libavresample   4.  0.  0 /  4.  0.  0\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'https://rr4---sn-qxoedn7k.googlevideo.com/videoplayback?expire=1713138378&ei=ahYcZuTIFqymlu8P8r6XOA&ip=34.173.202.63&id=o-ABHc7BLrSMZemPIGpLCaBZ6sMbAv_hynNxfxntLPZA05&itag=18&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=-K&mm=31%2C29&mn=sn-qxoedn7k%2Csn-qxo7rn7r&ms=au%2Crdu&mv=m&mvi=4&pl=17&initcwndbps=8598750&bui=AaUN6a2jSleE8AG16nk6AQ1yePr4ham-Hbm6PI8KxoYyop1J6uIeKvviCIPArNfKCQIROenunmMCvdkX&vprv=1&mime=video%2Fmp4&gir=yes&clen=36531513&ratebypass=yes&dur=636.621&lmt=1670960659854056&mt=1713116449&fvip=5&c=ANDROID_EMBEDDED_PLAYER&txp=5538434&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Cmime%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AJfQdSswRAIgAabj_uQsXF82lN8H10lbZYQGvTO0bIVUcy19mYNuMsUCIGg8BZLqzQRWRmZpevclcxWx4wcIqgVYu2iYONV27aRZ&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=ALClDIEwRgIhAOpbW7qsy3HvY87_dyJ5QIUfI34mXJWENpS3AA2VcODZAiEAvVXPhB6Wp-9IVFpoQAW7TMESns7QhLLjZvyaS_hHWaY%3D':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 0\n    compatible_brands: isommp42\n    encoder         : Google\n  Duration: 00:10:36.62, start: 0.000000, bitrate: 459 kb/s\n    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 360 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\nStream mapping:\n  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\nPress [q] to stop, [?] for help\nOutput #0, mp3, to 'pipe:':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 0\n    compatible_brands: isommp42\n    TSSE            : Lavf58.29.100\n    Stream #0:0(eng): Audio: mp3 (libmp3lame), 44100 Hz, stereo, fltp, 320 kb/s (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      encoder         : Lavc58.54.100 libmp3lame\nsize=   24870kB time=00:10:36.63 bitrate= 320.0kbits/s speed=44.5x    \nvideo:0kB audio:24869kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000542%\n","output_type":"stream"},{"name":"stdout","text":"Audio extraction complete.\nChunk 22, Google Speech Recognition could not understand audio\nSUMMARY\n:\n            The text discusses James Cameron's new movie, Avatar 2, and what to expect from the film. The author highlights that the movie will feature a simple but engaging storyline, groundbreaking technology, and an inspiring message on protecting the environment. The author watched the movie and found it visually stunning. The film's first half did not hold their attention, but the second half was thoroughly engrossing and exciting. The writer praises Cameron for utilizing his mastery of filmmaking to create an immersive experience in 3D, with attention to detail and invention to improve the viewing experience. They also discuss the character of Spider, who is a young human adopted by the Navi and whose motivations are unclear to the author. They encourage viewers to see the movie in theaters to appreciate Cameron's originality and environmental message. Finally, the author highlights the film's potential to inspire environmental activism and the importance of protecting the planet. \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **SUMMARY OF VIDEO**","metadata":{}},{"cell_type":"code","source":"generated_sample[\"text\"].split(\"SUMMARY\")[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:53:20.930993Z","iopub.execute_input":"2024-04-14T17:53:20.931286Z","iopub.status.idle":"2024-04-14T17:53:20.937104Z","shell.execute_reply.started":"2024-04-14T17:53:20.931261Z","shell.execute_reply":"2024-04-14T17:53:20.936177Z"},"trusted":true},"execution_count":204,"outputs":[{"execution_count":204,"output_type":"execute_result","data":{"text/plain":"\":\\n            The text discusses James Cameron's new movie, Avatar 2, and what to expect from the film. The author highlights that the movie will feature a simple but engaging storyline, groundbreaking technology, and an inspiring message on protecting the environment. The author watched the movie and found it visually stunning. The film's first half did not hold their attention, but the second half was thoroughly engrossing and exciting. The writer praises Cameron for utilizing his mastery of filmmaking to create an immersive experience in 3D, with attention to detail and invention to improve the viewing experience. They also discuss the character of Spider, who is a young human adopted by the Navi and whose motivations are unclear to the author. They encourage viewers to see the movie in theaters to appreciate Cameron's originality and environmental message. Finally, the author highlights the film's potential to inspire environmental activism and the importance of protecting the planet. \""},"metadata":{}}]},{"cell_type":"code","source":"print('length of dictionary with summaries',len(final))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:53:20.965350Z","iopub.execute_input":"2024-04-14T17:53:20.966216Z","iopub.status.idle":"2024-04-14T17:53:20.978276Z","shell.execute_reply.started":"2024-04-14T17:53:20.966192Z","shell.execute_reply":"2024-04-14T17:53:20.977304Z"},"trusted":true},"execution_count":207,"outputs":[{"execution_count":207,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"input_text=[]\nsummaries=[]\nfor key,value in final.items():\n    input_text.append(key)\n    summaries.append(value)  \n# Path where you want to save the CSV file which contains text and summaries\nfile_path = 'output.csv'\nwith open(file_path, 'w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['input_text', 'summaries'])\n    # Write data rows\n    for a, b in zip(input_text, summaries):\n        writer.writerow([a, b])","metadata":{"execution":{"iopub.status.busy":"2024-04-14T18:28:12.515284Z","iopub.execute_input":"2024-04-14T18:28:12.515698Z","iopub.status.idle":"2024-04-14T18:28:12.526623Z","shell.execute_reply.started":"2024-04-14T18:28:12.515666Z","shell.execute_reply":"2024-04-14T18:28:12.525768Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"markdown","source":"# EVALUATION OF GENERATED SUMMARIES USING G-EVAL ","metadata":{}},{"cell_type":"markdown","source":"Here we implement an example reference-free text evaluator using gpt-4, inspired by the G-Eval) framework which evaluates the quality of generated text using large language models. Unlike metrics like ROUGE or BERTScore that rely on comparison to reference summaries, the gpt-4 based evaluator assesses the quality of generated content based solely on the input prompt and text, without any ground truth references. This makes it applicable to new datasets and tasks where human references are sparse or unavailable.\n\nHere's an overview of this method:\n\nWe define four distinct criteria:\nRelevance: Evaluates if the summary includes only important information and excludes redundancies.\nCoherence: Assesses the logical flow and organization of the summary.\nConsistency: Checks if the summary aligns with the facts in the source document.\nFluency: Rates the grammar and readability of the summary.\nWe craft prompts for each of these criteria, taking the original document and the summary as inputs, and leveraging chain-of-thought generation and guiding the model to output a numeric score from 1-5 for each criteria.\nWe generate scores from gpt-4 with the defined prompts, comparing them across summaries.\nIn this demonstration, we're using a direct scoring function where gpt-4 generates a discrete score (1-5) for each metric. Normalizing the scores and taking a weighted sum could result in more robust, continuous scores that better reflect the quality and diversity of the summaries.","metadata":{}},{"cell_type":"code","source":"\n# def clean_whitespace(text):\n#     \"\"\"Replace more than two consecutive whitespaces with a single space.\"\"\"\n#     return re.sub(r'\\s{2,}', ' ', text)\n\n# def clean_csv(input_file_path, output_file_path):\n#     \"\"\"Read CSV, clean data, and write to a new CSV file.\"\"\"\n#     with open(input_file_path, mode='r', newline='') as infile, \\\n#          open(output_file_path, mode='w', newline='') as outfile:\n#         reader = csv.reader(infile)\n#         writer = csv.writer(outfile)\n#         headers = next(reader)\n#         writer.writerow(headers)\n#         for row in reader:\n#             cleaned_row = [clean_whitespace(cell) for cell in row]\n#             writer.writerow(cleaned_row)\n\n\n# input_csv_path = 'output.csv'\n# output_csv_path = 'cleaned.csv'\n\n# # Call the function to clean the CSV\n# clean_csv(input_csv_path, output_csv_path)\n\n\n\n\ndf=pd.read_csv('/kaggle/input/summarization-lllama/cleaned_summaries.csv')\n\n\n\n# Evaluation prompt template based on G-Eval\nEVALUATION_PROMPT_TEMPLATE = \"\"\"\nYou will be given one summary written for an article. Your task is to rate the summary on one metric.\nPlease make sure you read and understand these instructions very carefully. \nPlease keep this document open while reviewing, and refer to it as needed.\n\nEvaluation Criteria:\n\n{criteria}\n\nEvaluation Steps:\n\n{steps}\n\nExample:\n\nSource Text:\n\n{document}\n\nSummary:\n\n{summary}\n\nEvaluation Form (scores ONLY):\n\n- {metric_name}\n\"\"\"\n\n# Metric 1: Relevance\n\nRELEVANCY_SCORE_CRITERIA = \"\"\"\nRelevance(1-5) - selection of important content from the source. \\\nThe summary should include only important information from the source document. \\\nAnnotators were instructed to penalize summaries which contained redundancies and excess information.\n\"\"\"\n\nRELEVANCY_SCORE_STEPS = \"\"\"\n1. Read the summary and the source document carefully.\n2. Compare the summary to the source document and identify the main points of the article.\n3. Assess how well the summary covers the main points of the article, and how much irrelevant or redundant information it contains.\n4. Assign a relevance score from 1 to 5.\n\"\"\"\n\n# Metric 2: Coherence\n\nCOHERENCE_SCORE_CRITERIA = \"\"\"\nCoherence(1-5) - the collective quality of all sentences. \\\nWe align this dimension with the DUC quality question of structure and coherence \\\nwhereby \"the summary should be well-structured and well-organized. \\\nThe summary should not just be a heap of related information, but should build from sentence to a\\\ncoherent body of information about a topic.\"\n\"\"\"\n\nCOHERENCE_SCORE_STEPS = \"\"\"\n1. Read the article carefully and identify the main topic and key points.\n2. Read the summary and compare it to the article. Check if the summary covers the main topic and key points of the article,\nand if it presents them in a clear and logical order.\n3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n\"\"\"\n\n# Metric 3: Consistency\n\nCONSISTENCY_SCORE_CRITERIA = \"\"\"\nConsistency(1-5) - the factual alignment between the summary and the summarized source. \\\nA factually consistent summary contains only statements that are entailed by the source document. \\\nAnnotators were also asked to penalize summaries that contained hallucinated facts.\n\"\"\"\n\nCONSISTENCY_SCORE_STEPS = \"\"\"\n1. Read the article carefully and identify the main facts and details it presents.\n2. Read the summary and compare it to the article. Check if the summary contains any factual errors that are not supported by the article.\n3. Assign a score for consistency based on the Evaluation Criteria.\n\"\"\"\n\n# Metric 4: Fluency\n\nFLUENCY_SCORE_CRITERIA = \"\"\"\nFluency(1-3): the quality of the summary in terms of grammar, spelling, punctuation, word choice, and sentence structure.\n1: Poor. The summary has many errors that make it hard to understand or sound unnatural.\n2: Fair. The summary has some errors that affect the clarity or smoothness of the text, but the main points are still comprehensible.\n3: Good. The summary has few or no errors and is easy to read and follow.\n\"\"\"\n\nFLUENCY_SCORE_STEPS = \"\"\"\nRead the summary and evaluate its fluency based on the given criteria. Assign a fluency score from 1 to 3.\n\"\"\"\n\n# Function to simulate evaluation score fetching\ndef get_geval_score(\n    criteria: str, steps: str, document: str, summary: str, metric_name: str\n):\n    prompt = EVALUATION_PROMPT_TEMPLATE.format(\n        criteria=criteria,\n        steps=steps,\n        metric_name=metric_name,\n        document=document,\n        summary=summary,\n    )\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0,\n        max_tokens=5,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n    return response.choices[0].message.content\n\n# Evaluation criteria and steps as per different metrics\nevaluation_metrics = {\n    \"Relevance\": (RELEVANCY_SCORE_CRITERIA, RELEVANCY_SCORE_STEPS),\n    \"Coherence\": (COHERENCE_SCORE_CRITERIA, COHERENCE_SCORE_STEPS),\n    \"Consistency\": (CONSISTENCY_SCORE_CRITERIA, CONSISTENCY_SCORE_STEPS),\n    \"Fluency\": (FLUENCY_SCORE_CRITERIA, FLUENCY_SCORE_STEPS)\n}\n\n# Data structure to hold the evaluation results\n#data = {\"Evaluation Type\": [], \"Summary Type\": [], \"Score\": []}\nfinals=[] #list of dictionaries for each video\n# Process each summary in the DataFrame\nfor index, row in df.iterrows():\n    data = {\"Evaluation Type\": [], \"Summary Type\": [], \"Score\": []}\n    document = row['input_text']\n    summary = row['summaries']\n    summary_type = f\"Summary {index+1}\"  # Dynamic summary naming\n\n    # Apply each evaluation metric to the current summary\n    for eval_type, (criteria, steps) in evaluation_metrics.items():\n        result = get_geval_score(criteria, steps, document, summary, eval_type)\n        score_num = float(result.strip())  # Convert to float to handle scores like '4.5'\n        data[\"Evaluation Type\"].append(eval_type)\n        data[\"Summary Type\"].append(summary_type)\n        data[\"Score\"].append(score_num)\n    finals.append(data)    \n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T22:44:32.915447Z","iopub.execute_input":"2024-04-14T22:44:32.915971Z","iopub.status.idle":"2024-04-14T22:51:55.669279Z","shell.execute_reply.started":"2024-04-14T22:44:32.915939Z","shell.execute_reply":"2024-04-14T22:51:55.668541Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"finals","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:22:49.625907Z","iopub.execute_input":"2024-04-14T23:22:49.626546Z","iopub.status.idle":"2024-04-14T23:22:49.635357Z","shell.execute_reply.started":"2024-04-14T23:22:49.626514Z","shell.execute_reply":"2024-04-14T23:22:49.634491Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 1', 'Summary 1', 'Summary 1', 'Summary 1'],\n  'Score': [5.0, 5.0, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 2', 'Summary 2', 'Summary 2', 'Summary 2'],\n  'Score': [4.5, 4.5, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 3', 'Summary 3', 'Summary 3', 'Summary 3'],\n  'Score': [4.5, 4.5, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 4', 'Summary 4', 'Summary 4', 'Summary 4'],\n  'Score': [5.0, 5.0, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 5', 'Summary 5', 'Summary 5', 'Summary 5'],\n  'Score': [1.0, 1.0, 1.0, 2.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 6', 'Summary 6', 'Summary 6', 'Summary 6'],\n  'Score': [5.0, 5.0, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 7', 'Summary 7', 'Summary 7', 'Summary 7'],\n  'Score': [5.0, 5.0, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 8', 'Summary 8', 'Summary 8', 'Summary 8'],\n  'Score': [5.0, 4.5, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 9', 'Summary 9', 'Summary 9', 'Summary 9'],\n  'Score': [5.0, 5.0, 5.0, 3.0]},\n {'Evaluation Type': ['Relevance', 'Coherence', 'Consistency', 'Fluency'],\n  'Summary Type': ['Summary 10', 'Summary 10', 'Summary 10', 'Summary 10'],\n  'Score': [5.0, 5.0, 5.0, 3.0]}]"},"metadata":{}}]},{"cell_type":"code","source":"# Flatten the list of dictionaries into a single DataFrame\ndef highlight_max(s):\n    is_max = s == s.max()\n    return [\n        \"background-color: lightgreen\" if v else \"background-color: white\"\n        for v in is_max\n    ]\n\nall_data = []\nfor entry in finals:\n    for eval_type, summ_type, score in zip(entry['Evaluation Type'], entry['Summary Type'], entry['Score']):\n        all_data.append({'Evaluation Type': eval_type, 'Summary Type': summ_type, 'Score': score})\n\ndf = pd.DataFrame(all_data)\n\n# Pivot the DataFrame\npivot_df = df.pivot(index='Evaluation Type', columns='Summary Type', values='Score')\n\n\npivot_df = pivot_df.round(0).astype(int)\n\n# Display the rounded DataFrame\nprint(pivot_df)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:35:18.367313Z","iopub.execute_input":"2024-04-14T23:35:18.367985Z","iopub.status.idle":"2024-04-14T23:35:18.383211Z","shell.execute_reply.started":"2024-04-14T23:35:18.367951Z","shell.execute_reply":"2024-04-14T23:35:18.382292Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Summary Type     Summary 1  Summary 10  Summary 2  Summary 3  Summary 4  \\\nEvaluation Type                                                           \nCoherence                5           5          4          4          5   \nConsistency              5           5          5          5          5   \nFluency                  3           3          3          3          3   \nRelevance                5           5          4          4          5   \n\nSummary Type     Summary 5  Summary 6  Summary 7  Summary 8  Summary 9  \nEvaluation Type                                                         \nCoherence                1          5          5          4          5  \nConsistency              1          5          5          5          5  \nFluency                  2          3          3          3          3  \nRelevance                1          5          5          5          5  \n","output_type":"stream"}]},{"cell_type":"code","source":"pivot_df\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:35:21.985859Z","iopub.execute_input":"2024-04-14T23:35:21.986663Z","iopub.status.idle":"2024-04-14T23:35:21.998234Z","shell.execute_reply.started":"2024-04-14T23:35:21.986626Z","shell.execute_reply":"2024-04-14T23:35:21.997235Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Summary Type     Summary 1  Summary 10  Summary 2  Summary 3  Summary 4  \\\nEvaluation Type                                                           \nCoherence                5           5          4          4          5   \nConsistency              5           5          5          5          5   \nFluency                  3           3          3          3          3   \nRelevance                5           5          4          4          5   \n\nSummary Type     Summary 5  Summary 6  Summary 7  Summary 8  Summary 9  \nEvaluation Type                                                         \nCoherence                1          5          5          4          5  \nConsistency              1          5          5          5          5  \nFluency                  2          3          3          3          3  \nRelevance                1          5          5          5          5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Summary Type</th>\n      <th>Summary 1</th>\n      <th>Summary 10</th>\n      <th>Summary 2</th>\n      <th>Summary 3</th>\n      <th>Summary 4</th>\n      <th>Summary 5</th>\n      <th>Summary 6</th>\n      <th>Summary 7</th>\n      <th>Summary 8</th>\n      <th>Summary 9</th>\n    </tr>\n    <tr>\n      <th>Evaluation Type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Coherence</th>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Consistency</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Fluency</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Relevance</th>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pivot_df.to_csv('G_Eval_metrics_youtube_videos_llama_model.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T23:36:29.673953Z","iopub.execute_input":"2024-04-14T23:36:29.674758Z","iopub.status.idle":"2024-04-14T23:36:29.682765Z","shell.execute_reply.started":"2024-04-14T23:36:29.674727Z","shell.execute_reply":"2024-04-14T23:36:29.681864Z"},"trusted":true},"execution_count":22,"outputs":[]}]}